
### Portfolio

Hi, 
I am a Python developer. This portfolio represent work  on Machine Learning and NLP  .
### NLP_Sentiment_analysis_using_TextBlob.ipynb 
You calculate the sentiment using TextBlob or Vader. Based on the polarity and subjectivity, you determine whether it is a positive text or negative or neutral. For TextBlog, if the polarity is >0, it is considered positive, <0 -is considered negative and ==0 is considered neutral.

### Real time voice Recording to text using Sentiment Analysis.ipynb

With the help of textblob() and SpeechRecognization() ,here small concept about how  we convert audio which can record using microphone into text with the help of Textblob().Perform sentiment_analysis on the basis of polarity and subjectivity.

### Sentiment_analysis using TfidVectorization(one of the method of NLP).ipynb
 Tfidfvectorizer aim , is to convert a collection of raw documents to a matrix of TF-IDF features.With the help of TfidVectorization , model accuracy using Logistic Regression  Supervised Machine Learning Algorithm we can determine review of hotel_dataset by  analysing feedback ,given by customers.

###LogisticRegression
Logistic regression is a supervised learning classification algorithm used to predict the probability of a target variable. The nature of target or dependent variable is dichotomous, which means there would be only two possible classes.In simple words, the dependent variable is binary in nature having data coded as either 1 (stands for success/yes) or 0 (stands for failure/no).

###Decision_tree_Algorithm
 Decision Trees are a type of Supervised Machine Learning (that is you explain what the input is and what the corresponding output is in the training data) where the data is continuously split according to a certain parameter. The tree can be explained by two entities, namely decision nodes and leaves
 
 ###Randon_forest_algorithm
Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set. Random forests generally outperform decision trees, but their accuracy is lower than gradient boosted trees. However, data characteristics can affect their performance.
 
 
